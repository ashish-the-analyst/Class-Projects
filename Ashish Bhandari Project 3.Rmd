---
title: "Project 3"
author: "Ashish Bhandari"
date: "2022-11-15"
output:
  pdf_document: default
  html_document: default
editor_options: 
  markdown: 
    wrap: 72
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

**Introduction**

For this given project, we were given an article "The evidential value
of microspectrophotometry measurements made for pen inks" by Martyna et
al. Three color systems were used for ten replicates of each of forty
inks. Likelihood ratios were calculated as a measure of evidential value
for the spectral observations.

A likelihood ratio is a probability and can be calculated as:
$LR = \frac{\Pr(E|H_{p})}{\Pr(E |H_{d})}$

where, $H_{p}$ is the ink from the recovered item and the ink from the
control item are from the same pen and $H_d$ is the ink from the
recovered item and the ink from the control item are from the different
pen.

The likelihood ratios of three different univariates ("X", "Y" and "Z"
measure of colors) were constructed. These three variables were used to
find the relationship to an Omnibus likelihood ratio Dr.Saunders
constructed. The objective of the project is to describe and
characterize the relationship between those four Likelihood ratios, with
the ultimate goal of predicting the Omnibus LR.

We will be installing and loading the given libraries for this project.

```{r, message=FALSE, warning=FALSE}

# loading libraries
#install.packages("GGally")
#install.packages("rpart")
#install.packages("gamclass")
library(readxl)
library(tidyverse)
library(boot)
library(dplyr)
library(ggplot2)
library(GGally)
library(rpart)
library(mgcv)
library(gamair)
library(gamclass)
library(caret)
```

# Exploratory Data Analysis

After loading the libraries, we have loaded our dataset as a csv file.
We used the head function to check the vaiables used in our datasets.
There are a total of 7 columns and 820 rows as a dimension of the
dataset. Column "X" seems to be an unnessary column with no significant
impact on our findings, therefore I went ahead and removed the column
from our dataset. In our dataset, the within-source comparison
(wi)consists of of just 40 observations and the rest of the 780
observations are made up of between-source comparison (bw).

We looked at the dataset to find out if there were any missing values or
if there were any irregularities in the datasets. There were were not
any missing values in the given csv file. To remove the outliers in our
given dataset, I used the quartile function. I deduced the Q3 (3rd
quartile) and Q1 (1st quartile) of our dataset. I calculated the upper
limit and lower limit to find out if any of our variables are outside
the allowed limit. There was a variable on LLR.x column: 5.922 which was
calculated as an outlier and removed from the dataset. Next, we will be
splitting our dataset as type: between-source and within-source Then, we
will create histograms, scatterplots and boxplots.

```{r}
#loading data from the excel sheet
ink_data <- read.csv("C:/Users/ashis/Documents/Dakota State University/STAT 601/Project 3/dat.LLR.int.csv")

# reading the dataset
head(ink_data)

#dimension of the dataset
dim(ink_data)

# removing the column "X"
drop_col <- c("X")
ink_data2 <- ink_data[ , !(names(ink_data) %in% drop_col)]

# removing the outliers in the dataset using quartile function
outliers <- function(x) {

Q1 <- quantile(x, probs=.25)
Q3 <- quantile(x, probs=.75)
iqr = Q3-Q1

upper_limit = Q3 + (iqr*1.5)
lower_limit = Q1 - (iqr*1.5)

x > upper_limit | x < lower_limit
}

remove_out <- function(df, cols = names(df)) {
  for (col in cols) {
    df <- df[!outliers(df[[col]]),]
  }
  df
}

ink_data3 <- remove_out(ink_data2, c('LLR.x', "LLR.y", "LLR.z"))


#summary of the dataset
summary(ink_data3)

#subsetting within-source and between-source datasets

within_data <- data.frame(subset(ink_data3, Type == "wi"))
between_data <- data.frame(subset(ink_data3, Type == "bw"))


#plotting the data
layout(matrix(1:4, nrow = 2))
plot_data1 <- plot(ink_data3$Omni.LLR.int ~ ink_data3$LLR.x, main = 
        "LR of Omnibus vs LR of color X", xlab = "LR of Omnibus", ylab =
        " LR of color X")


plot_data2 <- plot(ink_data3$Omni.LLR.int ~ ink_data3$LLR.y, main = 
        "LR of Omnibus vs LR of color Y", xlab = "LR of Omnibus", ylab =
        " LR of color Y")

plot_data3 <- plot(ink_data3$Omni.LLR.int ~ ink_data3$LLR.z, main = 
        "LR of Omnibus vs LR of color Z", xlab = "LR of Omnibus", ylab =
        " LR of color Z")

#histogram plotting
layout(matrix(1:4, nrow = 2))
hist1 <- hist(ink_data3$Omni.LLR.int)
hist2 <- hist(ink_data3$LLR.x)
hist3 <- hist(ink_data3$LLR.y)
hist4 <- hist(ink_data3$LLR.z)

#boxplot using different variables

layout(matrix(1:4, nrow = 1))
x_plot <- boxplot(ink_data3$LLR.x, main = "Boxplot of LR of color X"
                  , ylab = "LR of X")

y_plot <- boxplot(ink_data3$LLR.y, main = "Boxplot of LR of color Y"
                  , ylab = "LR of Y")

z_plot <- boxplot(ink_data3$LLR.z, main = "Boxplot of LR of color Z"
                  , ylab = "LR of Z")
```

From our histogram plots, it seems like all of our four variables have a
left skewed. From our scatter plots, it is very difficult to derive a
conclusion about the relationship between Omnibus vs LR of X or Omnibus
vs LR of Y or Omnibus vs LF of Z. It seems like there is a non-linear
relationship between the Omnibus and three other marginal variables.
Also, since we removed the outlier from our dataset, all 3 boxplots does
not show any outliers. Additionally, we will be using correlation plot
to see if we can deduce anything from the plots.

```{r, message=FALSE}
#correlation plotting
plot_corr_within <- ggpairs(data = within_data, title = 
            " Fig 1: Correlation plot of within-source comparison")
plot_corr_within

plot_corr_between <- ggpairs(data = between_data, title = 
            " Fig 2 : Correlation plot of between-source comparison")
plot_corr_between

```

I have analyzed the above datasets separately for within-source and
between- source comparison. I created 2 different ggpairs plots to find
the correlation between the variables and we can see that there is a
non-linear relationship between all independent variables (LLR.x, LLR.y,
LLR.z) and Omnibus LR. A simple linear regression model will not be
sufficient to characterize the model, therefore I will be using a
generalized additive models (GAM) to measure the relatioship.

From the fig 1 ggpairs plot for within-source comparison, we can see
that there is a positive correlation of: 0.729 between LLR.x and
Omni.LLR.int. There is also a positive correlation of: 0.898 between
LLR.z and LLR.x *and* 0.928 between LLR.z and LLR.y.

From the fig 2 ggpairs plot for between-source comparison, we can see
that there is a positive correlation of 0.730 between LLR.x and
omni.LLR.int. There is a positive correlation of 0.599 between LLR.x and
LLR.z

```{r}
#aov analysis of the data
omni.aov <- aov(Omni.LLR.int ~ (LLR.x)+(LLR.y)+(LLR.z)+ as.factor(Type),
               data = ink_data3)
summary(omni.aov)

```

Using the aov function, we find out our sum of square means to be: 6562,
908 and 33 for LLR.x, LLR.y, LLR.z variables. We also find out that the
p-value for each of those variables to be less than 0.05, which
indicates all of the variables used in the model has significant impact
on the Omnibus variable and are significantly related.

```{r}
# gam model for within source comparison

set.seed(100)
# generating 80/20 split for training and testing datasets
within_data_split <- sample(1:nrow(within_data),0.80*nrow(within_data))

train_data1 <- within_data[within_data_split, ] 
test_data1 <- within_data[-within_data_split, ]

gam_within <- gam(Omni.LLR.int ~ s(LLR.x) + s(LLR.y) + s(LLR.z) ,
                  data = train_data1)
summary(gam_within)

cat("\n", "AIC of the model: ", AIC(gam_within))

par(mfrow=c(1,3))
plot(gam_within)

#predicting the Omnibus in the dataset
pred_omni1 <- predict(gam_within, newdata = test_data1, type = "response")


#cross validation error for the model
cv_accuracy1 <- CVgam(formula = Omni.LLR.int ~ s(LLR.x) + s(LLR.y) + s(LLR.z),
               within_data, nfold = 5)
```

GAM models were fit with splines to find out the relationship between
Omnibus and x,y and z variables. The adjusted r squared value for the
model is 1 and GCV value is 1.7837\*10\^6. From our summary, we have
seen that our variables have p-values of less than 0.05 which indicates
that these variables are statistically significant and indicates a
strong relationship between the variables. From the plots it is clear
that they have a non-linear relationship. The omnibus LR values
increases slowly with increase in the LLR.x and around a value of 3 then
tend to decrease.The omnibus values increase slowly with increase in
LLR.y around 1.5 and then tend to reduce.Similarly, non linear pattern
is observed with LLR.z where values increase around 2.5 and start to
decrease. AIC of the given model is: -393.1448. CV-mse-GAM for the given
model is : 0.0876

```{r}
# gam model for between source comparison

set.seed(100)
# generating 80/20 split for training and testing datasets
between_data_split <- sample(1:nrow(between_data),0.80*nrow(between_data))

train_data2 <- between_data[between_data_split, ] 
test_data2 <- between_data[-between_data_split, ]

gam_between <- gam(Omni.LLR.int ~ s(LLR.x) + s(LLR.y) + s(LLR.z) ,
                  data = train_data2)
summary(gam_between)
cat("\n", "AIC of the model: ", AIC(gam_between))

par(mfrow=c(1,3))
plot(gam_between)

#predicting the Omnibus in the dataset
pred_omni2 <- predict(gam_between, newdata = test_data2, type = "response")

#cross validation error for the model
cv_accuracy2 <- CVgam(formula = Omni.LLR.int ~ s(LLR.x) + s(LLR.y) + s(LLR.z),
               between_data, nfold = 5)


```

GAM models were fit with splines to find out the relationship between
Omnibus and x,y and z variables. The adjusted r squared value for the
model is 0.996 and GCV value is 0.04031. From our summary, we have seen
that our variables have p-values of less than 0.05 which indicates that
these variables are statistically significant. The plots indicate that
the values start to decrease until around -4 and start to increase
around 2 and decrease for LLR.x variable. For LLR.y variable, the plot
start to decrease around -2 and start to increase around 2 and decrease.
For LLR.z, the values start to decrease until -2 and increase around 2
and decrease again. AIC of the given model is: -231.7266. CV-mse-GAM for
the given model is : 0.0567

**Conclusion**

Initial investigation shows us that a non-linear relationship exist
between the variables and onmibus LR that Dr. Saunders created. GAM
models were created. As a conclusion, both the between-source comparison
and within-source comparison of the GAM model indicates that all the
three marginal LR variables are statistically significant in predicting
the Omnibus LR (Omni.LLR.int).

To improve the GAM model, we can use GAMboost and fit the model. We
could use anova to compare the performance of the models.

**References:**

1.  Hothorn, T., Everitt, B. S., Data II, C. A. L., Scaling, C. M., &
    Partitioning, C. R. (2017). HSAUR3: A Handbook of Statistical
    Analyses Using R.

2.  YouTube. (2022). Statistical Methods Series: Generalized Additive
    Models (GAMs). YouTube. Retrieved November 21, 2022, from
    <https://www.youtube.com/watch?v=Ukfvd8akfco&ab_channel=EcologicalForecasting>.

3.  Anal. Methods, 2013, 5, 6788-6795
